{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lightweight-lloyd",
   "metadata": {},
   "source": [
    "То, что нам понадобится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "balanced-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from operator import itemgetter as ig\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-anthony",
   "metadata": {},
   "source": [
    "Функция, вытаскивающая цену из строки, фильтрует все символы, кроме цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_price(val):\n",
    "    return float(''.join(filter(str.isdigit,val)))/1000000\n",
    "\n",
    "\n",
    "df_train = pd.read_hdf(\"../input/train_data.h5\")\n",
    "df_train['price'] = df_train['price'].map(parse_price)\n",
    "df_train['logprice'] = np.log(df_train['price'])\n",
    "df_test = pd.read_hdf(\"../input/test_data.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-damages",
   "metadata": {},
   "source": [
    "Объединяем таблицы в один датафрейм, чтобы выделить features ОДИНАКОВЫМ образом\n",
    "и для тренировочного, и для тестового набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train,df_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-turner",
   "metadata": {},
   "source": [
    "Разворачиваем колонку параметров, так как в ней расположена еще куча features\n",
    "поскольку это колонка словарей, ее легко превратить в новый dataFrame\n",
    "также здесь все пропущенные значения (NaN) заменяются на -1, чтобы быть каким-то числом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = df['params'].apply(pd.Series)\n",
    "params = params.fillna(-1)\n",
    "\n",
    "if \"Охрана\" not in df:\n",
    "    df = pd.concat([df,params],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-means",
   "metadata": {},
   "source": [
    "Попытка выбора признаков исходя из количества данных для них (попробовать признаки с более чем 400 вхождениями)\n",
    "была не слишком удачная - больше информации было из блока оценки eli5 в стартере2. \n",
    "Тем не менее, интересно было посмотреть. В будущем лучше использовать heatmap по отсутствующим данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_nunique = {feat:params[feat].nunique() for feat in params.columns}\n",
    "z = {k:v for k,v in sorted(feats_nunique.items(),key =ig(1))}\n",
    "caters = list(filter(lambda x: z[x] > 400,z.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-canberra",
   "metadata": {},
   "source": [
    "\n",
    "итоговые категориальные признаки, которые не будут преобразованы, а сразу отправятся на факторизацию\n",
    "они были определны частично по работе eli5 для простой модели дерева решений, частично подбором"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualit = [\"Новостройка:\",'Тип балкона:','Класс жилья:']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-brake",
   "metadata": {},
   "source": [
    "блок географических признаков.\n",
    "1. Из geo_block был выделен простой бинарный признак \"Москва-не Москва\"\n",
    "2. Из breadcrumbs был выделен не очень хорошо сдавливаемый категориальный признак района.\n",
    "Его бы в идеале превратить в ранговый (например, по удаленности от центра, в самом простом случае),\n",
    "но автоматически сделать это возможности нет. \n",
    "Поэтому здесь данные лишь сглаживаются по форме (отрезается \"метро\", например) и отправляются на факторизацию\n",
    "3. комбинированный ранговый признак - метро + МЦК. функции парсят колонку 'breadcrumbs' и возвращают 1, если есть\n",
    "соответствующий элемент\n",
    "для экономии кода одна и та же двухпараметрическая функция metro каррируется с параметром с помощью functools.partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "def region(lst):\n",
    "    if len(lst) >=2:\n",
    "        if lst[1].startswith('м.'):\n",
    "            return lst[1][3:]\n",
    "        else:\n",
    "            return lst[1]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def metro(val,x):\n",
    "    return int(any(x in k for k in val))\n",
    "    \n",
    "df['loc_cat']=df['breadcrumbs'].map(region)\n",
    "df['loc_cat'] = df['loc_cat'].factorize()[0]\n",
    "\n",
    "df['city_cat'] = df['geo_block'].map(lambda x: int(ig(0)(x) == 'г. Москва'))\n",
    "df['metro_cat'] = df['breadcrumbs'].map(partial(metro,x='м. ')) + df['breadcrumbs'].map(partial(metro,x='МЦК'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-royalty",
   "metadata": {},
   "source": [
    "4. признак охраны был введен на ранговой основе. Функция security парсит значения из колонки \"Охрана\"\n",
    "и при нахождении определенных кусков слов добавляет к итоговому результату какое-то количество баллов. \n",
    "В результате, чем охрана навороченнее - тем выше итоговое значение признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "def security(val):\n",
    "    if val == -1:\n",
    "        return 0\n",
    "    sm = 0\n",
    "    rest = {'огорожен','огра','закры','кпп','доступ'}\n",
    "    if any(w in val for w in rest):\n",
    "        sm += 1\n",
    "    cam = {'видео','камер'}\n",
    "    if any(w in val for w in cam):\n",
    "        sm += 1\n",
    "    if 'консьерж' in val:\n",
    "        sm += 1\n",
    "    if 'круглосут' in val:\n",
    "        sm += 1\n",
    "    return sm \n",
    "\n",
    "\n",
    "df['secur_cat']=df['Охрана:'].map(security)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-spencer",
   "metadata": {},
   "source": [
    "5. блок парковки изначально состоял из двух признаков, очевидно следующих из предлагаемых в колонке данных:\n",
    "числа машиномест и типа парковки. \n",
    "Функции parking_spaces и parking_loc парсят данные из колонки \"Парковка\":; первая находит максимум из чисел, \n",
    "лежащих в строке данных - это и есть число машиномест (если оно там есть), и возвращает его натуральный логарифм,\n",
    "чтобы разброс данных был меньше и модель кушала лучше\n",
    "вторая функция была призвана ранжировать признак по наличию подземной или наземной парковки, или обоих типов\n",
    "Потом по результатам тестирования второй признак оказался не полезным для результата, поэтому не использовался - \n",
    "остался только первый\n",
    "6. в типе здания были просто порезаны окончания, чтобы число вариантов было меньше. \n",
    "можно было бы статистически проанализировать веса категорий по гистограмме, но распределение относительно цены само по \n",
    "себе все равно такое, что сильного влияния не оказывает. сам признак полезный, влияет на ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parking_spaces(val):\n",
    "    if val!=-1 and any(l.isdigit() for l in val.split()):\n",
    "        v = val.split()\n",
    "        num = max(list(filter(str.isdigit,v)),key=int)\n",
    "        return np.log(int(num)) if num else -1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def parking_loc(val):\n",
    "    if val!=-1:\n",
    "        res = ''\n",
    "        if 'подзем' in val:\n",
    "            res += '1'\n",
    "        if 'назем' or 'открыта' in val:\n",
    "            res += '2'\n",
    "        if len(res) == 0:\n",
    "            return -1\n",
    "        elif len(res) == 1:\n",
    "            return int(res)\n",
    "        else:\n",
    "            return 3\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "def edifice(val):\n",
    "    if val != -1:\n",
    "        v = val.lower()[:-2]\n",
    "    return -1\n",
    "         \n",
    "df['parkspaces_cat'] = df['Парковка:'].map(parking_spaces)\n",
    "#df['parkloc_cat'] = df['Парковка:'].map(parking_loc)\n",
    "df['type_cat'] = df['Тип здания:'].map(edifice).factorize()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-cisco",
   "metadata": {},
   "source": [
    "7-11. набор остальных признаков из блока params. Все из них пропарсены; признак \"Этаж:\" разделен на два - собственно этаж\n",
    "квартиры и этажность здания. \n",
    "Все признаки были протестированы, и оставлены только те, включение которых улучшало результат обучения.\n",
    "Полезными оказались: этаж,этажность,общая площадь, количество комнат, высота потолков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_end(val,en):\n",
    "    return float(val[:en]) if val != -1 else int(val)\n",
    "\n",
    "def floor(val):\n",
    "    if type(val)==str and '/' in val:\n",
    "        return list(map(int,val.split('/')))\n",
    "    else:\n",
    "        return int(val),-1\n",
    "\n",
    "def rooms(val):\n",
    "    if int(val) < 9:\n",
    "        return int(val)\n",
    "    else:\n",
    "        return 9\n",
    "    \n",
    "#df['kitchen_cat'] = df['Площадь кухни:'].map(partial(parse_end,en=-3))\n",
    "df['floor_cat'],df['height_cat'] = zip(*df['Этаж:'].map(floor))\n",
    "df[\"area_cat\"] = df[\"Общая площадь:\"].map(lambda x: float(x[:-3]))\n",
    "df['rooms_cat'] = df['Количество комнат:'].map(rooms)\n",
    "df['ceiling_cat'] = df['Высота потолков:'].map(partial(parse_end,en=-2))\n",
    "#df['living_cat'] = df['Жилая комната:'].map(partial(parse_end,en=-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-genius",
   "metadata": {},
   "source": [
    "Небольшой блок фильтрации данных от выбросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['area_cat']<1000]\n",
    "df = df[df['ceiling_cat'] != 100.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-psychology",
   "metadata": {},
   "source": [
    "Зафейленная идея парсить дату публикации. сами данные настолько неоднородные, что выгоднее вообще оказалось\n",
    "исключить признак из рассмотрения. но технически сделать было интересно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHS = {'января':'01','февраля':'02','марта':'03','апреля':'04','мая':'05','июня':'06','июля':'07',\n",
    "         'августа':'08','сентября':'09','октября':'10','ноября':'11','декабря':'12'}\n",
    "def datefilter(st):\n",
    "    if st[0].isdigit():\n",
    "        v = st.split()\n",
    "        d,m = v[0],v[1]\n",
    "        y = v[2] if len(v)>2 else '2018'\n",
    "        return int(MONTHS[m]),y\n",
    "    else:\n",
    "        return -1,-1\n",
    "\n",
    "#df['month_cat'],df['year_cat'] = zip(*df['Дата публикации:'].apply(datefilter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-highlight",
   "metadata": {},
   "source": [
    "Блок факторизации категориальных признаков, выбранных ранее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in qualit:\n",
    "    df[f'{feat}_cat'] = df[feat].factorize()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-venture",
   "metadata": {},
   "source": [
    "Окончательная выборка признаков для обучения - это все столбцы,имеющие _сat в названии\n",
    "а далее - странный трюк. Чтобы модели было чуть легче отделять отсутствие данных, сделаем его \n",
    "более отстоящим от основных групп данных, заменив -1 на -100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = list(filter(lambda x: '_cat' in x,df.columns))\n",
    "\n",
    "df[cat_feats] = df[cat_feats].replace(-1,-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-margin",
   "metadata": {},
   "source": [
    "Разделим уже подготовленный датафрейм обратно на обучающую и тестовую выборки по наличию значения в столбце price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[~df['price'].isnull()].copy()\n",
    "df_test = df[df['price'].isnull()].copy()\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-torture",
   "metadata": {},
   "source": [
    "Cформируем наборы данных для обучения и теста по подготовленному ранее списку категорий cat_feats - всего у нас 14 признаков!\n",
    "Слава прихотливой индексации в pandas! как же это удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[cat_feats]\n",
    "y_train = df_train['price']\n",
    "\n",
    "X_test = df_test[cat_feats]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-charter",
   "metadata": {},
   "source": [
    "Самое главное - собственно выбор модели и ее параметров.\n",
    "Очевидно, наверное, что простая модель регрессии на такой разнородной, дырявой и обширной выборке будет не слишком эффективна.\n",
    "Поэтому выбор стоит сделать в пользу ансамблей моделей - они лежат или в sklearn.ensemble, или реализованы\n",
    "в сторонних библиотеках типа XGBoost\n",
    "Вариантов ансамблевых моделей по-простому три: бэггинг, бустинг и стекинг.\n",
    "Первый строит множество однородных моделей на поднаборах обучающих данных и потом обучается на их результатах\n",
    "Второй \"прокачивает работу\" ансамбля слабых моделей, итеративно обучая каждый следующий шаг ансамбля на ошибках предыдущего шага\n",
    "Третий объединяет работу разнородных моделей в \"стопку\" так, чтобы они компенсировали слабые места друг друга\n",
    "\n",
    "Поскольку конечным желаемым вариантом работы от нас требуют mae - mean absolute error, т.е. смещение, вариантов выбора ансамблей\n",
    "два - или бэггинг, или бустинг. Стекинг направлен на уменьшение разброса результатов работы модели (кстати, это работает\n",
    "на данной выборке!), поэтому здесь не совсем подходит. Я выбрал подход бэггинга.\n",
    "\n",
    "Поскольку мы уже работали с деревьями решений, логично в качестве основного эстиматора для ансамбля выбрать дерево -\n",
    "то есть или DecisionTreeRegressor, или его более рандомизированный вариант ExtraTreeRegressor из sklearn.tree\n",
    "\n",
    "Это оставляет перед следующими вариантами:\n",
    "- конвенционный бэггинг в sklearn.ensemble.BaggingRegressor c заданием или DecisionTree, или ExtraTree в качестве базы\n",
    "- случайный лес в sklearn.ensemble.RandomForestRegressor\n",
    "- экстремальный случайный лес в sklearn.ensemble.ExtraTreesRegressor\n",
    "\n",
    "Протестировав все, оказалось, что ExtraTreesRegressor дает наилучшие результаты за вполне разумное время (порядка 13-15 секунд)\n",
    "с заданными параметрами. К слову о них - количество эстиматоров было выбрано оптимальным (больше, меньше = хуже, а в случае \n",
    "больше еще и дольше =)), max_features позволяет взять не все признаки разом для обучения, а только часть из них. Взяв порядка \n",
    "корня из 14 (у нас ведь 14 признаков) получаем чуть больше 3 - именно это число и оказалось оптимальным, увеличив быстродействие\n",
    "работы модели без потери эффективности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(n_estimators=77, random_state=0, max_features=3)\n",
    "scores = cross_val_score(model,X_train,y_train,cv=5,scoring='neg_mean_absolute_error')\n",
    "np.mean(scores),np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['price'] = y_pred\n",
    "print(df_test.shape)\n",
    "df_test[['id','price']].to_csv(\"../output/os14.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-documentary",
   "metadata": {},
   "source": [
    "Средняя относительная ошибка - отношение MAE к средней цене по выборке. Параметр чисто для себя, как более привычный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_relative_error = np.mean(scores)/np.mean(df_test['price']) * 100\n",
    "mean_relative_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
